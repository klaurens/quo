{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a1d5fbd-2631-42e6-9d22-b94e31f30e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kenji\\miniforge3\\envs\\project\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:model_params is:\n",
      " {'type': 'attribute_mask_rcnn', 'model_dir': '', 'use_tpu': False, 'isolate_session_state': False, 'architecture': {'parser': 'attribute_maskrcnn_parser', 'backbone': 'spinenet', 'min_level': 3, 'max_level': 7, 'use_bfloat16': False, 'space_to_depth_block_size': 1, 'multilevel_features': 'identity', 'include_mask': True, 'mask_target_size': 28, 'num_classes': 47, 'num_attributes': 294}, 'attribute_maskrcnn_parser': {'output_size': [1280, 1280], 'rpn_match_threshold': 0.7, 'rpn_unmatched_threshold': 0.3, 'rpn_batch_size_per_im': 256, 'rpn_fg_fraction': 0.5, 'aug_rand_hflip': True, 'aug_scale_min': 0.5, 'aug_scale_max': 2.0, 'skip_crowd_during_training': True, 'max_num_instances': 100, 'mask_crop_size': 112}, 'anchor': {'num_scales': 1, 'aspect_ratios': [1.0, 2.0, 0.5], 'anchor_size': 3.0}, 'fpn': {'fpn_feat_dims': 256, 'use_separable_conv': False, 'use_batch_norm': True}, 'nasfpn': {'fpn_feat_dims': 256, 'num_repeats': 5, 'use_separable_conv': False, 'init_drop_connect_rate': None, 'block_fn': 'conv'}, 'rpn_head': {'anchors_per_location': None, 'num_convs': 1, 'num_filters': 256, 'use_separable_conv': False, 'use_batch_norm': True, 'cast_to_float32': False}, 'frcnn_head': {'num_convs': 4, 'num_filters': 256, 'use_separable_conv': False, 'num_fcs': 1, 'fc_dims': 1024, 'use_batch_norm': True}, 'mrcnn_head': {'num_convs': 4, 'num_filters': 256, 'use_separable_conv': False, 'use_batch_norm': True, 'class_agnostic_mask_pred': False}, 'rpn_score_loss': {'rpn_batch_size_per_im': 256}, 'rpn_box_loss': {'huber_loss_delta': 0.1111111111111111}, 'frcnn_box_loss': {'huber_loss_delta': 1.0}, 'roi_proposal': {'rpn_pre_nms_top_k': 2000, 'rpn_post_nms_top_k': 1000, 'rpn_nms_threshold': 0.7, 'rpn_score_threshold': 0.0, 'rpn_min_size_threshold': 0.0, 'test_rpn_pre_nms_top_k': 1000, 'test_rpn_post_nms_top_k': 1000, 'test_rpn_nms_threshold': 0.7, 'test_rpn_score_threshold': 0.0, 'test_rpn_min_size_threshold': 0.0, 'use_batched_nms': False}, 'roi_sampling': {'num_samples_per_image': 512, 'fg_fraction': 0.25, 'fg_iou_thresh': 0.5, 'bg_iou_thresh_hi': 0.5, 'bg_iou_thresh_lo': 0.0, 'mix_gt_boxes': True}, 'mask_sampling': {'num_mask_samples_per_image': 128}, 'batch_norm_activation': {'batch_norm_momentum': 0.99, 'batch_norm_epsilon': 0.001, 'batch_norm_trainable': True, 'use_sync_bn': True, 'activation': 'swish'}, 'dropblock': {'dropblock_keep_prob': None, 'dropblock_size': None}, 'resnet': {'resnet_depth': 50, 'init_drop_connect_rate': None}, 'spinenet': {'model_id': '143', 'init_drop_connect_rate': 0.2, 'use_native_resize_op': False}, 'spinenet_mbconv': {'model_id': '49', 'se_ratio': 0.2, 'init_drop_connect_rate': None, 'use_native_resize_op': False}, 'postprocess': {'apply_nms': True, 'use_batched_nms': False, 'max_total_size': 100, 'nms_iou_threshold': 0.5, 'score_threshold': 0.05, 'pre_nms_num_boxes': 1000}, 'train': {'iterations_per_loop': 100, 'train_batch_size': 256, 'total_steps': 33750, 'num_cores_per_replica': None, 'input_partition_dims': None, 'optimizer': {'type': 'momentum', 'momentum': 0.9}, 'learning_rate': {'type': 'step', 'warmup_learning_rate': 0.0, 'warmup_steps': 500, 'init_learning_rate': 0.28, 'learning_rate_levels': [0.028, 0.0028], 'learning_rate_steps': [31875, 33125]}, 'checkpoint': {'path': '', 'prefix': '', 'skip_variables_regex': ''}, 'frozen_variable_prefix': None, 'train_file_pattern': '', 'train_dataset_type': 'tfrecord', 'transpose_input': True, 'regularization_variable_regex': '.*(kernel|weight):0$', 'l2_weight_decay': 4e-05, 'gradient_clip_norm': 0.0, 'space_to_depth_block_size': 1}, 'eval': {'type': 'box_and_mask', 'eval_batch_size': 8, 'eval_samples': 1158, 'min_eval_interval': 180, 'eval_timeout': None, 'num_steps_per_eval': 1000, 'eval_file_pattern': '', 'eval_dataset_type': 'tfrecord', 'use_json_file': True, 'val_json_file': '', 'per_category_metrics': False}, 'predict': {'predict_batch_size': 8}, 'enable_summary': True, 'mode': 'infer', 'transpose_input': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:model_params is:\n",
      " {'type': 'attribute_mask_rcnn', 'model_dir': '', 'use_tpu': False, 'isolate_session_state': False, 'architecture': {'parser': 'attribute_maskrcnn_parser', 'backbone': 'spinenet', 'min_level': 3, 'max_level': 7, 'use_bfloat16': False, 'space_to_depth_block_size': 1, 'multilevel_features': 'identity', 'include_mask': True, 'mask_target_size': 28, 'num_classes': 47, 'num_attributes': 294}, 'attribute_maskrcnn_parser': {'output_size': [1280, 1280], 'rpn_match_threshold': 0.7, 'rpn_unmatched_threshold': 0.3, 'rpn_batch_size_per_im': 256, 'rpn_fg_fraction': 0.5, 'aug_rand_hflip': True, 'aug_scale_min': 0.5, 'aug_scale_max': 2.0, 'skip_crowd_during_training': True, 'max_num_instances': 100, 'mask_crop_size': 112}, 'anchor': {'num_scales': 1, 'aspect_ratios': [1.0, 2.0, 0.5], 'anchor_size': 3.0}, 'fpn': {'fpn_feat_dims': 256, 'use_separable_conv': False, 'use_batch_norm': True}, 'nasfpn': {'fpn_feat_dims': 256, 'num_repeats': 5, 'use_separable_conv': False, 'init_drop_connect_rate': None, 'block_fn': 'conv'}, 'rpn_head': {'anchors_per_location': None, 'num_convs': 1, 'num_filters': 256, 'use_separable_conv': False, 'use_batch_norm': True, 'cast_to_float32': False}, 'frcnn_head': {'num_convs': 4, 'num_filters': 256, 'use_separable_conv': False, 'num_fcs': 1, 'fc_dims': 1024, 'use_batch_norm': True}, 'mrcnn_head': {'num_convs': 4, 'num_filters': 256, 'use_separable_conv': False, 'use_batch_norm': True, 'class_agnostic_mask_pred': False}, 'rpn_score_loss': {'rpn_batch_size_per_im': 256}, 'rpn_box_loss': {'huber_loss_delta': 0.1111111111111111}, 'frcnn_box_loss': {'huber_loss_delta': 1.0}, 'roi_proposal': {'rpn_pre_nms_top_k': 2000, 'rpn_post_nms_top_k': 1000, 'rpn_nms_threshold': 0.7, 'rpn_score_threshold': 0.0, 'rpn_min_size_threshold': 0.0, 'test_rpn_pre_nms_top_k': 1000, 'test_rpn_post_nms_top_k': 1000, 'test_rpn_nms_threshold': 0.7, 'test_rpn_score_threshold': 0.0, 'test_rpn_min_size_threshold': 0.0, 'use_batched_nms': False}, 'roi_sampling': {'num_samples_per_image': 512, 'fg_fraction': 0.25, 'fg_iou_thresh': 0.5, 'bg_iou_thresh_hi': 0.5, 'bg_iou_thresh_lo': 0.0, 'mix_gt_boxes': True}, 'mask_sampling': {'num_mask_samples_per_image': 128}, 'batch_norm_activation': {'batch_norm_momentum': 0.99, 'batch_norm_epsilon': 0.001, 'batch_norm_trainable': True, 'use_sync_bn': True, 'activation': 'swish'}, 'dropblock': {'dropblock_keep_prob': None, 'dropblock_size': None}, 'resnet': {'resnet_depth': 50, 'init_drop_connect_rate': None}, 'spinenet': {'model_id': '143', 'init_drop_connect_rate': 0.2, 'use_native_resize_op': False}, 'spinenet_mbconv': {'model_id': '49', 'se_ratio': 0.2, 'init_drop_connect_rate': None, 'use_native_resize_op': False}, 'postprocess': {'apply_nms': True, 'use_batched_nms': False, 'max_total_size': 100, 'nms_iou_threshold': 0.5, 'score_threshold': 0.05, 'pre_nms_num_boxes': 1000}, 'train': {'iterations_per_loop': 100, 'train_batch_size': 256, 'total_steps': 33750, 'num_cores_per_replica': None, 'input_partition_dims': None, 'optimizer': {'type': 'momentum', 'momentum': 0.9}, 'learning_rate': {'type': 'step', 'warmup_learning_rate': 0.0, 'warmup_steps': 500, 'init_learning_rate': 0.28, 'learning_rate_levels': [0.028, 0.0028], 'learning_rate_steps': [31875, 33125]}, 'checkpoint': {'path': '', 'prefix': '', 'skip_variables_regex': ''}, 'frozen_variable_prefix': None, 'train_file_pattern': '', 'train_dataset_type': 'tfrecord', 'transpose_input': True, 'regularization_variable_regex': '.*(kernel|weight):0$', 'l2_weight_decay': 4e-05, 'gradient_clip_norm': 0.0, 'space_to_depth_block_size': 1}, 'eval': {'type': 'box_and_mask', 'eval_batch_size': 8, 'eval_samples': 1158, 'min_eval_interval': 180, 'eval_timeout': None, 'num_steps_per_eval': 1000, 'eval_file_pattern': '', 'eval_dataset_type': 'tfrecord', 'use_json_file': True, 'val_json_file': '', 'per_category_metrics': False}, 'predict': {'predict_batch_size': 8}, 'enable_summary': True, 'mode': 'infer', 'transpose_input': False}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Setting up TPUEstimator...\n",
      "WARNING:tensorflow:From C:\\Users\\Kenji\\AppData\\Local\\Temp\\ipykernel_10864\\274583933.py:80: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Kenji\\AppData\\Local\\Temp\\ipykernel_10864\\274583933.py:80: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Kenji\\AppData\\Local\\Temp\\tmprruk_o4p\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Kenji\\AppData\\Local\\Temp\\tmprruk_o4p\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\Kenji\\\\AppData\\\\Local\\\\Temp\\\\tmprruk_o4p', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'local', '_evaluation_master': 'local', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1, num_shards=None, num_cores_per_replica=None, per_host_input_for_training=2, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\Kenji\\\\AppData\\\\Local\\\\Temp\\\\tmprruk_o4p', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'local', '_evaluation_master': 'local', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1, num_shards=None, num_cores_per_replica=None, per_host_input_for_training=2, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:_TPUContext: eval_on_tpu True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:_TPUContext: eval_on_tpu True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Exporting the model...\n",
      "\n",
      "creating folder\n",
      "INFO:tensorflow:Creating base dir: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating base dir: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running infer on CPU/GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running infer on CPU/GPU\n",
      "C:\\Users\\Kenji\\miniforge3\\envs\\project\\lib\\site-packages\\keras\\legacy_tf_layers\\convolutional.py:536: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  warnings.warn('`tf.layers.conv2d` is deprecated and '\n",
      "C:\\Users\\Kenji\\miniforge3\\envs\\project\\lib\\site-packages\\keras\\engine\\base_layer_v1.py:1676: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "C:\\Users\\Kenji\\miniforge3\\envs\\project\\lib\\site-packages\\keras\\legacy_tf_layers\\pooling.py:554: UserWarning: `tf.layers.max_pooling2d` is deprecated and will be removed in a future version. Please use `tf.keras.layers.MaxPooling2D` instead.\n",
      "  warnings.warn('`tf.layers.max_pooling2d` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Kenji\\Desktop\\fashionpedia-run\\ops\\spatial_transform_ops.py:455: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Kenji\\Desktop\\fashionpedia-run\\ops\\spatial_transform_ops.py:455: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "C:\\Users\\Kenji\\miniforge3\\envs\\project\\lib\\site-packages\\keras\\legacy_tf_layers\\core.py:236: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  warnings.warn('`tf.layers.dense` is deprecated and '\n",
      "C:\\Users\\Kenji\\miniforge3\\envs\\project\\lib\\site-packages\\keras\\legacy_tf_layers\\convolutional.py:1660: UserWarning: `tf.layers.conv2d_transpose` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2DTranspose` instead.\n",
      "  warnings.warn('`tf.layers.conv2d_transpose` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Kenji\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow\\python\\saved_model\\signature_def_utils_impl.py:200: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Kenji\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow\\python\\saved_model\\signature_def_utils_impl.py:200: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from tf2model/tf2_model-1.data-00000-of-00001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from tf2model/tf2_model-1.data-00000-of-00001\n"
     ]
    },
    {
     "ename": "DataLossError",
     "evalue": "2 root error(s) found.\n  (0) Data loss: Unable to open table file tf2model\\tf2_model-1.data-00000-of-00001: Data loss: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\n\t [[node save/RestoreV2 (defined at \\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:970) ]]\n  (1) Data loss: Unable to open table file tf2model\\tf2_model-1.data-00000-of-00001: Data loss: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\n\t [[node save/RestoreV2 (defined at \\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:970) ]]\n\t [[save/RestoreV2/_13]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'save/RestoreV2':\n  File \"\\miniforge3\\envs\\project\\lib\\runpy.py\", line 197, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"\\miniforge3\\envs\\project\\lib\\runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n    app.launch_new_instance()\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n    app.start()\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n    self.io_loop.start()\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n    self.asyncio_loop.run_forever()\n  File \"\\miniforge3\\envs\\project\\lib\\asyncio\\windows_events.py\", line 321, in run_forever\n    super().run_forever()\n  File \"\\miniforge3\\envs\\project\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n    self._run_once()\n  File \"\\miniforge3\\envs\\project\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n    handle._run()\n  File \"\\miniforge3\\envs\\project\\lib\\asyncio\\events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n    await self.process_one()\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n    await dispatch(*args)\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n    await result\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n    reply_content = await reply_content\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n    res = shell.run_cell(\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n    result = self._run_cell(\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n    result = runner(coro)\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"\\AppData\\Local\\Temp\\ipykernel_10864\\274583933.py\", line 124, in <module>\n    export(\"saved_models2\",\n  File \"\\AppData\\Local\\Temp\\ipykernel_10864\\274583933.py\", line 104, in export\n    export_path = estimator.export_saved_model(\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 720, in export_saved_model\n    return self._export_all_saved_models(\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 854, in _export_all_saved_models\n    self._add_meta_graph_for_mode(\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\tpu\\tpu_estimator.py\", line 2883, in _add_meta_graph_for_mode\n    (super(TPUEstimator, self)._add_meta_graph_for_mode(\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 970, in _add_meta_graph_for_mode\n    tf.compat.v1.train.Saver(sharded=True))\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 836, in __init__\n    self.build()\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 848, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 876, in _build\n    self.saver_def = self._builder._build_internal(  # pylint: disable=protected-access\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 509, in _build_internal\n    restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 383, in _AddShardedRestoreOps\n    self._AddRestoreOps(\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 335, in _AddRestoreOps\n    all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 583, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1489, in restore_v2\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 748, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3561, in _create_op_internal\n    ret = Operation(\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2045, in __init__\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDataLossError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32m~\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1375\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1375\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOpError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1359\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1358\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extend_graph()\n\u001b[1;32m-> 1359\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_tf_sessionrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1360\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1451\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_tf_sessionrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[0;32m   1450\u001b[0m                         run_metadata):\n\u001b[1;32m-> 1451\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionRun_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1452\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1453\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mDataLossError\u001b[0m: 2 root error(s) found.\n  (0) Data loss: Unable to open table file tf2model\\tf2_model-1.data-00000-of-00001: Data loss: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\n\t [[{{node save/RestoreV2}}]]\n  (1) Data loss: Unable to open table file tf2model\\tf2_model-1.data-00000-of-00001: Data loss: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\n\t [[{{node save/RestoreV2}}]]\n\t [[save/RestoreV2/_13]]\n0 successful operations.\n0 derived errors ignored.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mDataLossError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 124\u001b[0m\n\u001b[0;32m    117\u001b[0m   tf\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mRename(export_path, export_dir)\n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m# export(\"saved_models\",\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;66;03m#      \"checkpoints/fashionpedia-spinenet-143/model.ckpt\",\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;66;03m#      \"attribute_mask_rcnn\",\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m#      \"configs/yaml/spinenet143_amrcnn.yaml\",)\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m \u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaved_models2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m     \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtf2model/tf2_model-1.data-00000-of-00001\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m     \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mattribute_mask_rcnn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m     \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfigs/yaml/spinenet143_amrcnn.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 104\u001b[0m, in \u001b[0;36mexport\u001b[1;34m(export_dir, checkpoint_path, model, config_file, params_override, use_tpu, batch_size, image_size, input_type, input_name, output_image_info, output_normalized_coordinates, cast_num_detections_to_float, cast_detection_classes_to_float)\u001b[0m\n\u001b[0;32m    101\u001b[0m   tf\u001b[38;5;241m.\u001b[39mlogging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCreating base dir: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m, dir_name)\n\u001b[0;32m    102\u001b[0m   tf\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mMakeDirs(dir_name)\n\u001b[1;32m--> 104\u001b[0m export_path \u001b[38;5;241m=\u001b[39m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport_saved_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_dir_base\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdir_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserving_input_receiver_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserving_input_receiver_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m tf\u001b[38;5;241m.\u001b[39mlogging\u001b[38;5;241m.\u001b[39minfo(\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExported SavedModel to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, renaming to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    111\u001b[0m     export_path, export_dir)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mExists(export_dir):\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:720\u001b[0m, in \u001b[0;36mEstimator.export_saved_model\u001b[1;34m(self, export_dir_base, serving_input_receiver_fn, assets_extra, as_text, checkpoint_path, experimental_mode)\u001b[0m\n\u001b[0;32m    716\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn input_receiver_fn must be defined.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    718\u001b[0m input_receiver_fn_map \u001b[38;5;241m=\u001b[39m {experimental_mode: serving_input_receiver_fn}\n\u001b[1;32m--> 720\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_export_all_saved_models\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_dir_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_receiver_fn_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43massets_extra\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43massets_extra\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrip_default_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:854\u001b[0m, in \u001b[0;36mEstimator._export_all_saved_models\u001b[1;34m(self, export_dir_base, input_receiver_fn_map, assets_extra, as_text, checkpoint_path, strip_default_attrs)\u001b[0m\n\u001b[0;32m    852\u001b[0m   save_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    853\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_receiver_fn_map\u001b[38;5;241m.\u001b[39mget(ModeKeys\u001b[38;5;241m.\u001b[39mPREDICT):\n\u001b[1;32m--> 854\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_meta_graph_for_mode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbuilder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_receiver_fn_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m      \u001b[49m\u001b[43msave_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPREDICT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m      \u001b[49m\u001b[43mstrip_default_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrip_default_attrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    861\u001b[0m   save_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_variables:\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\tpu\\tpu_estimator.py:2883\u001b[0m, in \u001b[0;36mTPUEstimator._add_meta_graph_for_mode\u001b[1;34m(self, builder, input_receiver_fn_map, checkpoint_path, save_variables, mode, export_tags, check_variables, strip_default_attrs)\u001b[0m\n\u001b[0;32m   2880\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOne of export_to_cpu and export_to_tpu must be true.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   2882\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_export_to_cpu:\n\u001b[1;32m-> 2883\u001b[0m   (\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mTPUEstimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_meta_graph_for_mode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2884\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbuilder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2885\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_receiver_fn_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2886\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2887\u001b[0m \u001b[43m      \u001b[49m\u001b[43msave_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2888\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2889\u001b[0m \u001b[43m      \u001b[49m\u001b[43mexport_tags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_tags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2890\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcheck_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2891\u001b[0m \u001b[43m      \u001b[49m\u001b[43mstrip_default_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrip_default_attrs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   2893\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_export_to_tpu \u001b[38;5;129;01mand\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m model_fn_lib\u001b[38;5;241m.\u001b[39mModeKeys\u001b[38;5;241m.\u001b[39mPREDICT:\n\u001b[0;32m   2894\u001b[0m   input_receiver_fn_map \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   2895\u001b[0m       _INFERENCE_ON_TPU_MODE: input_receiver_fn_map[mode]\n\u001b[0;32m   2896\u001b[0m   }\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:977\u001b[0m, in \u001b[0;36mEstimator._add_meta_graph_for_mode\u001b[1;34m(self, builder, input_receiver_fn_map, checkpoint_path, save_variables, mode, export_tags, check_variables, strip_default_attrs)\u001b[0m\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_variables:\n\u001b[0;32m    976\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 977\u001b[0m     \u001b[43mgraph_saver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    978\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m tf\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    979\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCould not load all requested variables from checkpoint. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    980\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease make sure your model_fn does not expect variables \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    981\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthat were not saved in the checkpoint.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    982\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEncountered error with mode `\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m` while restoring \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    983\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint from: `\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m`. Full Traceback:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    984\u001b[0m                mode, checkpoint_path, e)\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1303\u001b[0m, in \u001b[0;36mSaver.restore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1301\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_eager(save_path, build_save\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, build_restore\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1302\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1303\u001b[0m     \u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaver_def\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore_op_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1304\u001b[0m \u001b[43m             \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaver_def\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename_tensor_name\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mNotFoundError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1306\u001b[0m   \u001b[38;5;66;03m# There are three common conditions that might cause this error:\u001b[39;00m\n\u001b[0;32m   1307\u001b[0m   \u001b[38;5;66;03m# 0. The file is missing. We ignore here, as this is checked above.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1311\u001b[0m   \u001b[38;5;66;03m# 1. The checkpoint would not be loaded successfully as is. Try to parse\u001b[39;00m\n\u001b[0;32m   1312\u001b[0m   \u001b[38;5;66;03m# it as an object-based checkpoint.\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow\\python\\client\\session.py:967\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    964\u001b[0m run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 967\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    969\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[0;32m    970\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1190\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;66;03m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[0;32m   1189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_fetches \u001b[38;5;129;01mor\u001b[39;00m final_targets \u001b[38;5;129;01mor\u001b[39;00m (handle \u001b[38;5;129;01mand\u001b[39;00m feed_dict_tensor):\n\u001b[1;32m-> 1190\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_fetches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1191\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mfeed_dict_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1193\u001b[0m   results \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1368\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1365\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1368\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_run_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1369\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1370\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1371\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1394\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124monly supports NHWC tensor format\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m message:\n\u001b[0;32m   1390\u001b[0m   message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mA possible workaround: Try disabling Grappler optimizer\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1391\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mby modifying the config for creating the session eg.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1392\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124msession_config.graph_options.rewrite_options.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1393\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisable_meta_optimizer = True\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1394\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(e)(node_def, op, message)\n",
      "\u001b[1;31mDataLossError\u001b[0m: 2 root error(s) found.\n  (0) Data loss: Unable to open table file tf2model\\tf2_model-1.data-00000-of-00001: Data loss: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\n\t [[node save/RestoreV2 (defined at \\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:970) ]]\n  (1) Data loss: Unable to open table file tf2model\\tf2_model-1.data-00000-of-00001: Data loss: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\n\t [[node save/RestoreV2 (defined at \\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:970) ]]\n\t [[save/RestoreV2/_13]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'save/RestoreV2':\n  File \"\\miniforge3\\envs\\project\\lib\\runpy.py\", line 197, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"\\miniforge3\\envs\\project\\lib\\runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n    app.launch_new_instance()\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n    app.start()\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n    self.io_loop.start()\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n    self.asyncio_loop.run_forever()\n  File \"\\miniforge3\\envs\\project\\lib\\asyncio\\windows_events.py\", line 321, in run_forever\n    super().run_forever()\n  File \"\\miniforge3\\envs\\project\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n    self._run_once()\n  File \"\\miniforge3\\envs\\project\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n    handle._run()\n  File \"\\miniforge3\\envs\\project\\lib\\asyncio\\events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n    await self.process_one()\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n    await dispatch(*args)\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n    await result\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n    reply_content = await reply_content\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n    res = shell.run_cell(\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n    result = self._run_cell(\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n    result = runner(coro)\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"\\AppData\\Local\\Temp\\ipykernel_10864\\274583933.py\", line 124, in <module>\n    export(\"saved_models2\",\n  File \"\\AppData\\Local\\Temp\\ipykernel_10864\\274583933.py\", line 104, in export\n    export_path = estimator.export_saved_model(\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 720, in export_saved_model\n    return self._export_all_saved_models(\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 854, in _export_all_saved_models\n    self._add_meta_graph_for_mode(\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\tpu\\tpu_estimator.py\", line 2883, in _add_meta_graph_for_mode\n    (super(TPUEstimator, self)._add_meta_graph_for_mode(\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 970, in _add_meta_graph_for_mode\n    tf.compat.v1.train.Saver(sharded=True))\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 836, in __init__\n    self.build()\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 848, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 876, in _build\n    self.saver_def = self._builder._build_internal(  # pylint: disable=protected-access\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 509, in _build_internal\n    restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 383, in _AddShardedRestoreOps\n    self._AddRestoreOps(\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 335, in _AddRestoreOps\n    all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 583, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1489, in restore_v2\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 748, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3561, in _create_op_internal\n    ret = Operation(\n  File \"\\miniforge3\\envs\\project\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2045, in __init__\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import functools\n",
    "import os\n",
    "from absl import flags\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.compat.v1 import estimator as tf_estimator\n",
    "\n",
    "# from projects.fashionpedia.configs import factory\n",
    "# from projects.fashionpedia.serving import serving\n",
    "from configs import factory\n",
    "from serving import serving\n",
    "from hyperparameters import params_dict\n",
    "from tensorflow.python.ops import control_flow_util  # pylint: disable=g-direct-tensorflow-import\n",
    "\n",
    "def export(export_dir,\n",
    "           checkpoint_path,\n",
    "           model,\n",
    "           config_file='',\n",
    "           params_override='',\n",
    "           use_tpu=False,\n",
    "           batch_size=1,\n",
    "           image_size=(640, 640),\n",
    "           input_type='image_tensor',\n",
    "           input_name='input',\n",
    "           output_image_info=True,\n",
    "           output_normalized_coordinates=False,\n",
    "           cast_num_detections_to_float=False,\n",
    "           cast_detection_classes_to_float=False):\n",
    "  \"\"\"Exports the SavedModel.\"\"\"\n",
    "  control_flow_util.enable_control_flow_v2()\n",
    "\n",
    "  params = factory.config_generator(model)\n",
    "  if config_file:\n",
    "    params = params_dict.override_params_dict(\n",
    "        params, config_file, is_strict=True)\n",
    "  # Use `is_strict=False` to load params_override with run_time variables like\n",
    "  # `train.num_shards`.\n",
    "  params = params_dict.override_params_dict(\n",
    "      params, params_override, is_strict=False)\n",
    "  if not use_tpu:\n",
    "    params.override({\n",
    "        'architecture': {\n",
    "            'use_bfloat16': use_tpu,\n",
    "        },\n",
    "    }, is_strict=True)\n",
    "  if batch_size is None:\n",
    "    params.override({\n",
    "        'postprocess': {\n",
    "            'use_batched_nms': True,\n",
    "        }\n",
    "    })\n",
    "  params.validate()\n",
    "  params.lock()\n",
    "\n",
    "  model_params = dict(\n",
    "      params.as_dict(),\n",
    "      use_tpu=use_tpu,\n",
    "      mode=tf_estimator.ModeKeys.PREDICT,\n",
    "      transpose_input=False)\n",
    "  tf.logging.info('model_params is:\\n %s', model_params)\n",
    "\n",
    "  if model in ['attribute_mask_rcnn']:\n",
    "    model_fn = serving.serving_model_fn_builder(\n",
    "        use_tpu, output_image_info, output_normalized_coordinates,\n",
    "        cast_num_detections_to_float, cast_detection_classes_to_float)\n",
    "    serving_input_receiver_fn = functools.partial(\n",
    "        serving.serving_input_fn,\n",
    "        batch_size=batch_size,\n",
    "        desired_image_size=image_size,\n",
    "        stride=(2 ** params.architecture.max_level),\n",
    "        input_type=input_type,\n",
    "        input_name=input_name)\n",
    "  else:\n",
    "    raise ValueError('The model type `{} is not supported.'.format(model))\n",
    "\n",
    "  print(' - Setting up TPUEstimator...')\n",
    "  estimator = tf_estimator.tpu.TPUEstimator(\n",
    "      model_fn=model_fn,\n",
    "      model_dir=None,\n",
    "      config=tf_estimator.tpu.RunConfig(\n",
    "          tpu_config=tf_estimator.tpu.TPUConfig(iterations_per_loop=1),\n",
    "          master='local',\n",
    "          evaluation_master='local'),\n",
    "      params=model_params,\n",
    "      use_tpu=use_tpu,\n",
    "      train_batch_size=batch_size,\n",
    "      predict_batch_size=batch_size,\n",
    "      export_to_tpu=use_tpu,\n",
    "      export_to_cpu=True)\n",
    "\n",
    "  print(' - Exporting the model...')\n",
    "\n",
    "  dir_name = os.path.dirname(export_dir)\n",
    "  print(dir_name)\n",
    "\n",
    "  if not tf.gfile.Exists(dir_name):\n",
    "    print('creating folder')\n",
    "    tf.logging.info('Creating base dir: %s', dir_name)\n",
    "    tf.gfile.MakeDirs(dir_name)\n",
    "\n",
    "  export_path = estimator.export_saved_model(\n",
    "      export_dir_base=dir_name,\n",
    "      serving_input_receiver_fn=serving_input_receiver_fn,\n",
    "      checkpoint_path=checkpoint_path)\n",
    "\n",
    "  tf.logging.info(\n",
    "      'Exported SavedModel to %s, renaming to %s',\n",
    "      export_path, export_dir)\n",
    "\n",
    "  if tf.gfile.Exists(export_dir):\n",
    "    tf.logging.info('Deleting existing SavedModel dir: %s', export_dir)\n",
    "    tf.gfile.DeleteRecursively(export_dir)\n",
    "\n",
    "  tf.gfile.Rename(export_path, export_dir)\n",
    "    \n",
    "# export(\"saved_models\",\n",
    "#      \"checkpoints/fashionpedia-spinenet-143/model.ckpt\",\n",
    "#      \"attribute_mask_rcnn\",\n",
    "#      \"configs/yaml/spinenet143_amrcnn.yaml\",)\n",
    "\n",
    "export(\"saved_models2\",\n",
    "     \"tf2model/tf2_model-1.data-00000-of-00001\",\n",
    "     \"attribute_mask_rcnn\",\n",
    "     \"configs/yaml/spinenet143_amrcnn.yaml\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873676a9-c2c1-4315-83bc-b6b988cefbba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
