{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65e44651-1e10-478f-ab0d-ee6e7cd2c02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from utils import mask_utils, box_utils\n",
    "from utils.object_detection import visualization_utils\n",
    "from pycocotools import mask as mask_api\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import os \n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "model = tf.saved_model.load(os.getenv('MODEL_DIR'))\n",
    "\n",
    "def infer(image_pattern):\n",
    "\n",
    "    label_map_dict = {}\n",
    "    with open('datasets/fashionpedia_label_map.csv', 'r') as csv_file:\n",
    "        reader = csv_file.readlines()\n",
    "        for row in reader:\n",
    "            k, v = row.split(':')\n",
    "            id_index = int(k)\n",
    "            name = v\n",
    "            label_map_dict[id_index] = {\n",
    "                'id': id_index,\n",
    "                'name': name,\n",
    "            }\n",
    "    res = []\n",
    "    image_files = glob.glob(image_pattern)\n",
    "    for i, image_file in tqdm(enumerate(image_files), total = len(image_files)):\n",
    "        print(f'processing image {i}, {image_file}', end = '\\t\\t\\t\\t\\r')\n",
    "        \n",
    "        image = Image.open(image_file)    \n",
    "        image_array = np.array(image)[:,:,:3] #remove alpha channel\n",
    "        input_tensor = tf.convert_to_tensor(np.expand_dims(image_array, axis=0), dtype=tf.uint8)\n",
    "        \n",
    "        # Perform inference\n",
    "        \n",
    "        serving_default_fn = model.signatures['serving_default']\n",
    "        output_results = serving_default_fn(input_tensor)\n",
    "            \n",
    "        image_with_detections_list = []\n",
    "        \n",
    "                \n",
    "        num_detections = int(output_results['num_detections'][0])\n",
    "        np_boxes = output_results['detection_boxes'][0, :num_detections]\n",
    "        width, height = image.size\n",
    "        \n",
    "        np_image_info = output_results['image_info'][0]\n",
    "        np_boxes = np_boxes / np.tile(np_image_info[1:2, :], (1, 2))\n",
    "        ymin, xmin, ymax, xmax = np.split(np_boxes, 4, axis=-1)\n",
    "        ymin = ymin * height\n",
    "        ymax = ymax * height\n",
    "        xmin = xmin * width\n",
    "        xmax = xmax * width\n",
    "        \n",
    "        np_boxes = np.concatenate([ymin, xmin, ymax, xmax], axis=-1)\n",
    "        np_scores = output_results['detection_scores'][0, :num_detections]\n",
    "        np_classes = output_results['detection_classes'][0, :num_detections]\n",
    "        np_classes = np_classes.numpy().astype(np.int32)\n",
    "        np_attributes = output_results['detection_attributes'][\n",
    "        0, :num_detections, :]\n",
    "        \n",
    "        np_masks = None\n",
    "        if 'detection_masks' in output_results:\n",
    "            np_masks = output_results['detection_masks'][0, :num_detections]\n",
    "            np_masks = mask_utils.paste_instance_masks(\n",
    "                np_masks, box_utils.yxyx_to_xywh(np_boxes), height, width)\n",
    "            encoded_masks = [\n",
    "                mask_api.encode(np.asfortranarray(np_mask))\n",
    "                for np_mask in list(np_masks)]\n",
    "        \n",
    "        np_image = (image_array.reshape(height, width, 3).astype(np.uint8))\n",
    "        image_with_detections = (\n",
    "                visualization_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                    np_image,\n",
    "                    np_boxes,\n",
    "                    np_classes,\n",
    "                    np_scores,\n",
    "                    label_map_dict,\n",
    "                    instance_masks=np_masks,\n",
    "                    use_normalized_coordinates=False,\n",
    "                    max_boxes_to_draw=15,\n",
    "                    min_score_thresh=0.3))\n",
    "        image_with_detections_list.append(image_with_detections)\n",
    "\n",
    "        res.append({\n",
    "                'image_file': image_file,\n",
    "                'boxes': np_boxes,\n",
    "                'classes': np_classes,\n",
    "                'scores': np_scores.numpy(),\n",
    "                'attributes': np_attributes,\n",
    "                'masks': encoded_masks,\n",
    "            })\n",
    "        # plt.imshow(image_with_detections_list[0])\n",
    "        # plt.show()\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc6b508a-e956-46d9-82c3-615fd7ecf352",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5327fbfe6a5e4948a490e4a8860ff3d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1026 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 18min 53s./project-cluster-index/lovebonito_tops/top\\zurie-flare-sleeve-blouse\\hy5117-031.jpg\t\t\t\tzxu0vpzm.jpg\t\t\t\t\t\t1_egiun13li3dmefv2.jpg\t\t\t\t\t\t\t\t\t\n",
      "Wall time: 13min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "output = infer('../../project-cluster-index/lovebonito_tops/top/**/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18bbdcc5-108b-4eef-baf4-9739dfb45018",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.save('lovebonito_output', (output), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078161fd-dbf1-4806-9cc3-938e192fbe41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycocotools.mask as mask_util\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "with open('datasets/fashionpedia_label_map.csv', 'r') as f:\n",
    "    mapping = f.readlines()\n",
    "\n",
    "for item_idx in range(len(output)):\n",
    "    # item_idx=25\n",
    "    for i in range(len(output[item_idx]['masks'])):    \n",
    "        # if output[item_idx]['classes'][i] in (1,2,3):\n",
    "            # 1:shirt, blouse\n",
    "            # 2:top, t-shirt, sweatshirt\n",
    "            # 3:sweater\n",
    "    \n",
    "            print(mapping[output[item_idx]['classes'][i] - 1], output[item_idx]['boxes'][i],  output[item_idx]['scores'][i])\n",
    "            fig, ax = plt.subplots(1, 5, figsize=(10,10))\n",
    "            img = cv2.imread(output[item_idx]['image_file'])\n",
    "            image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            ax[0].imshow(image)\n",
    "            ax[0].set_title('Original')\n",
    "    \n",
    "             # Encoded mask string\n",
    "            encoded_mask_string = output[item_idx]['masks'][i]\n",
    "            \n",
    "            # Decode the mask\n",
    "            decoded_mask = mask_util.decode(encoded_mask_string)\n",
    "            \n",
    "            # Visualize the mask        \n",
    "            ax[1].imshow(decoded_mask)        \n",
    "            ax[1].set_title('Mask')\n",
    "    \n",
    "            masked_img = np.einsum('hwc,hw->hwc', image, decoded_mask)\n",
    "            masked_img[masked_img == 0] = 255\n",
    "            ax[2].imshow(masked_img)\n",
    "            ax[2].set_title('Masked')\n",
    "    \n",
    "            #Crop to bounding boxes        \n",
    "            y1, x1, y2, x2 = np.ceil(output[item_idx]['boxes'][i]).astype(int)\n",
    "            crop_img = image[y1:y2, x1:x2]\n",
    "            ax[3].imshow(crop_img)\n",
    "            ax[3].set_title('Cropped')\n",
    "    \n",
    "            crop_masked_img = masked_img[y1:y2, x1:x2]\n",
    "            crop_masked_img[crop_masked_img == 0] = 255\n",
    "            ax[4].imshow(crop_masked_img)\n",
    "            ax[4].set_title('Masked + Cropped')\n",
    "           \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
